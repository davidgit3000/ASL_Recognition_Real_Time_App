# ğŸ¤Ÿ ASL Sign Language Translator

A comprehensive machine learning project for real-time American Sign Language (ASL) recognition using **dual model architecture**: Random Forest for static signs and PyTorch Transformer for dynamic motion-based signs.

## âœ¨ Features

- ğŸ¯ **Dual Model System**: Toggle between Random Forest (static signs) and Transformer (dynamic signs)
- ğŸ“¹ **Real-Time Detection**: Live camera feed with MediaPipe hand tracking
- ğŸ”Š **Text-to-Speech**: Automatic sentence building and voice output
- ğŸŒ **Web Interface**: Beautiful Flask-based UI with model switching
- ğŸ¤– **PyTorch Transformer**: Sequence-based recognition for motion signs
- ğŸŒ² **Random Forest**: Fast, accurate static sign classification
- â• **Add New Signs**: Web UI for Random Forest, CLI for Transformer
- ğŸ“Š **Model Analytics**: Real-time confidence scores and buffer status
- ğŸ¨ **Modern UI**: Responsive design with TailwindCSS

## ğŸ—ï¸ Project Structure

```
asl_sign_model/
â”œâ”€â”€ app.py                          # Flask web application (dual model)
â”œâ”€â”€ config.py                       # Central configuration
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # Project documentation
â”œâ”€â”€ CHANGELOG.md                    # Version history
â”‚
â”œâ”€â”€ shell_cmd/                      # Shell scripts
â”‚   â”œâ”€â”€ run_webapp.sh               # Quick start Flask app
â”‚   â””â”€â”€ check_labels.sh             # Check dataset labels
â”‚
â”œâ”€â”€ scripts/                        # Training & data collection
â”‚   â”œâ”€â”€ collect_images.py           # Collect static images (RF)
â”‚   â”œâ”€â”€ collect_sequences.py        # Collect sequences (Transformer)
â”‚   â”œâ”€â”€ add_new_sign.py             # Add signs to RF dataset
â”‚   â”œâ”€â”€ add_new_signs_tf.py         # Add signs to Transformer dataset
â”‚   â”œâ”€â”€ remove_signs.py             # Remove signs from dataset
â”‚   â”œâ”€â”€ check_labels.py             # Check dataset labels (Python)
â”‚   â”œâ”€â”€ create_dataset.py           # Process RF training data
â”‚   â”œâ”€â”€ train_classifier.py         # Train Random Forest
â”‚   â”œâ”€â”€ train_transformer_pytorch.py # Train Transformer
â”‚   â”œâ”€â”€ inference_classifier.py     # CLI inference (RF)
â”‚   â””â”€â”€ inference_transformer.py    # CLI inference (Transformer)
â”‚
â”œâ”€â”€ transformer/                    # Transformer model architecture
â”‚   â””â”€â”€ transformer_model_pytorch.py
â”‚
â”œâ”€â”€ models/                         # Saved models
â”‚   â”œâ”€â”€ rf_model/                   # Random Forest models
â”‚   â”‚   â”œâ”€â”€ model.pickle
â”‚   â”‚   â””â”€â”€ data.pickle
â”‚   â”œâ”€â”€ tf_model/                   # Transformer models
â”‚   â”‚   â”œâ”€â”€ transformer_model.pth
â”‚   â”‚   â”œâ”€â”€ label_encoder.pickle
â”‚   â”‚   â””â”€â”€ sequences.pickle
â”‚   â””â”€â”€ backup/                     # Model backups
â”‚
â”œâ”€â”€ templates/                      # HTML templates
â”‚   â””â”€â”€ index.html                  # Main web interface
â”‚
â”œâ”€â”€ static/                         # Frontend assets
â”‚   â””â”€â”€ app.js                      # JavaScript (model toggle, UI)
â”‚
â”œâ”€â”€ docs/                           # Documentation
â”‚   â””â”€â”€ DATASET_MANAGEMENT.md       # Dataset management guide
â”‚
â”œâ”€â”€ data/                           # Training images
â”œâ”€â”€ saved_predictions/              # Saved screenshots
â””â”€â”€ confusion_matrix/               # Model evaluation plots

```

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
# Create virtual environment (recommended)
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install requirements
pip install -r requirements.txt
```

### 2. Launch Web Application

```bash
# Quick start (recommended)
./shell_cmd/run_webapp.sh

# Or manually
python app.py
```

Open browser: **http://localhost:5001**

### 3. Use the Application

1. **Start Camera**: Click "â–¶ï¸ Start Camera"
2. **Choose Model**:
   - Random Forest: Instant static sign detection (A, B, C)
   - Transformer: Motion-based dynamic signs (hello, good morning)
3. **Perform Signs**: Show hand signs to camera
4. **Build Sentences**: Signs auto-add at high confidence
5. **Speak**: Click "ğŸ”Š Speak Sentence" for text-to-speech

---

## ğŸ“Š Dual Model System

### Random Forest (Static Signs)

**Best for**: Letters (A-Z), numbers, static gestures

**Features**:

- âš¡ Instant predictions (no buffering)
- ğŸ¯ High accuracy for static signs
- ğŸ”„ Add new signs via web interface
- ğŸ“¸ Single-frame classification

**Usage**:

```bash
# Train Random Forest
python scripts/train_classifier.py

# CLI inference
python scripts/inference_classifier.py
```

### PyTorch Transformer (Dynamic Signs)

**Best for**: Motion-based signs (hello, how are you, good morning)

**Features**:

- ğŸ¬ Sequence-based (30 frames)
- ğŸ§  Captures temporal patterns
- ğŸ¯ Better for dynamic motions
- â±ï¸ 2-second cooldown between predictions

**Usage**:

```bash
# Train Transformer
python scripts/train_transformer_pytorch.py

# CLI inference
python scripts/inference_transformer.py
```

### Model Comparison

| Feature                | Random Forest | Transformer       |
| ---------------------- | ------------- | ----------------- |
| **Speed**              | Instant       | 3-sec buffer      |
| **Input**              | 1 frame       | 30 frames         |
| **Best For**           | Static (A-Z)  | Dynamic (hello)   |
| **Add Sign**           | Web UI âœ…     | CLI only          |
| **Accuracy (Static)**  | Excellent     | Good              |
| **Accuracy (Dynamic)** | Poor          | Excellent         |
| **Device**             | CPU           | Apple Silicon GPU |

---

## ğŸ“ Training Workflows

### Random Forest Training (Static Signs)

```bash
# 1. Collect images
python scripts/collect_images.py

# 2. Create dataset
python scripts/create_dataset.py

# 3. Train model
python scripts/train_classifier.py

# 4. Test inference
python scripts/inference_classifier.py
```

### Transformer Training (Dynamic Signs)

```bash
# 1. Collect sequences (30 frames each)
python scripts/collect_sequences.py A B C hello "good morning"

# 2. Train model
python scripts/train_transformer_pytorch.py

# 3. Test inference
python scripts/inference_transformer.py
```

---

## â• Adding New Signs

### Random Forest (Web Interface)

1. Open web app: `http://localhost:5001`
2. Click "â• Add New Sign"
3. Enter sign name
4. Collect 100 images via webcam
5. Model retrains automatically âœ…

### Random Forest (CLI)

```bash
# Add new sign incrementally
python scripts/add_new_sign.py <sign_name>

# Retrain model
python scripts/train_classifier.py
```

### Transformer (CLI Only)

```bash
# Add new sign with sequences
python scripts/add_new_signs_tf.py <sign_name> --sequences 15

# Retrain model
python scripts/train_transformer_pytorch.py

# Restart Flask app to load new model
```

---

## ğŸ—‘ï¸ Removing Signs

```bash
# Remove specific signs from dataset
python scripts/remove_signs.py <sign1> <sign2>

# Example
python scripts/remove_signs.py "bad sign" rest

# Retrain model after removal
python scripts/train_transformer_pytorch.py  # or train_classifier.py
```

---

## ğŸ” Check Dataset Labels

View all signs in your datasets:

```bash
# Python script (detailed)
python scripts/check_labels.py

# Bash script (quick)
./shell_cmd/check_labels.sh
```

**Output includes**:

- ğŸ“Š Random Forest signs and sample counts
- ğŸ¤– Transformer signs and sequence counts
- ğŸ”„ Comparison showing common/unique signs
- ğŸ“ˆ Dataset statistics

---

## âš™ï¸ Configuration

All settings in `config.py`:

### Data Collection

```python
SIGNS_TO_COLLECT = ["A", "B", "C", "hello"]
DATASET_SIZE = 200  # Images per sign (RF)
SEQUENCES_PER_SIGN = 20  # Sequences per sign (Transformer)
SEQUENCE_LENGTH = 30  # Frames per sequence
```

### Model Settings

```python
# Random Forest
N_ESTIMATORS = 100
MAX_DEPTH = 10

# Transformer
EPOCHS = 50
BATCH_SIZE = 32
LEARNING_RATE = 0.001
MODEL_TYPE = 'lightweight'  # or 'powerful'
```

### Detection Settings

```python
MIN_DETECTION_CONFIDENCE = 0.5
CONFIDENCE_THRESHOLD_HIGH = 80  # Green
CONFIDENCE_THRESHOLD_MEDIUM = 60  # Orange
CONFIDENCE_THRESHOLD_UNKNOWN = 50  # Unknown
```

### File Paths

```python
# Random Forest
MODEL_PATH = "./models/rf_model/model.pickle"
DATA_PICKLE_PATH = "./models/rf_model/data.pickle"

# Transformer
TRANSFORMER_MODEL_PATH = "./models/tf_model/transformer_model.pth"
TRANSFORMER_LABEL_ENCODER_PATH = "./models/tf_model/label_encoder.pickle"
SEQUENCES_PICKLE_PATH = "./models/tf_model/sequences.pickle"
```

---

## ğŸŒ Web API Endpoints

### Prediction

```bash
POST /predict
Content-Type: application/json

{
  "landmarks": [[...]]  # MediaPipe hand landmarks
}

Response:
{
  "success": true,
  "prediction": "hello",
  "confidence": 92.5,
  "model_type": "transformer",
  "buffer_status": "30/30"
}
```

### Toggle Model

```bash
POST /toggle_model
Content-Type: application/json

{
  "model_type": "transformer"  # or "random_forest"
}
```

### Reset Buffer

```bash
POST /reset_buffer

Response:
{
  "success": true,
  "message": "Buffer reset"
}
```

### Model Info

```bash
GET /model_info

Response:
{
  "success": true,
  "model_type": "random_forest",
  "num_signs": 13,
  "signs": ["A", "B", "C", ...]
}
```

---

## ğŸ¯ Model Performance

### Random Forest

- **Test Accuracy**: **98.73%** ğŸ¯
- **Per-Class Accuracy**:
  - A: 100% (precision: 1.00, recall: 1.00)
  - B: 100% (precision: 1.00, recall: 1.00)
  - C: 100% (precision: 1.00, recall: 1.00)
  - a: 99% (precision: 1.00, recall: 0.97)
  - d: 100% (precision: 1.00, recall: 1.00)
  - fine: 99% (precision: 0.97, recall: 1.00)
  - good morning: 99% (precision: 1.00, recall: 0.97)
  - good night: 96% (precision: 0.99, recall: 0.94)
  - hello: 100% (precision: 1.00, recall: 1.00)
  - how are you?: 99% (precision: 1.00, recall: 0.99)
  - i: 97% (precision: 1.00, recall: 0.95)
  - i love you: 98% (precision: 0.95, recall: 1.00)
  - my name is: 97% (precision: 0.94, recall: 1.00)
  - nice to meet you: 100% (precision: 1.00, recall: 1.00)
  - v: 100% (precision: 1.00, recall: 1.00)
  - yes: 99% (precision: 0.98, recall: 1.00)
- **Features**: 126 (2 hands Ã— 21 landmarks Ã— 3 coords)
- **Speed**: Instant (<10ms)
- **Device**: CPU
- **Training**: 16 signs, 4716 samples

### Transformer

- **Test Accuracy**: **98.72%** ğŸ¯
- **Per-Class Accuracy**:
  - A: 100.00%
  - B: 100.00%
  - C: 100.00%
  - I love you: 100.00%
  - d: 83.33%
  - good morning: 100.00%
  - good night: 100.00%
  - hello: 100.00%
  - how are you: 100.00%
  - i: 100.00%
  - nice to meet you: 100.00%
  - v: 100.00%
  - yes: 83.33%
- **Parameters**: ~50K (lightweight) or ~200K (powerful)
- **Speed**: 3-second buffer + 2-second cooldown
- **Device**: Apple Silicon GPU (MPS)
- **Training**: 13 signs, 50 epochs

---

## ğŸ’¡ Tips for Best Results

### Data Collection

1. **Consistent lighting** - same environment for training/testing
2. **Clear hand visibility** - avoid occlusion
3. **Steady camera** - mount or stabilize
4. **Varied angles** - slight variations improve generalization
5. **Multiple sequences** - 15-20 for dynamic signs, 10 for static

### Model Selection

- **Static signs** (A-Z, numbers): Use Random Forest
- **Dynamic signs** (hello, goodbye): Use Transformer
- **Mixed dataset**: Train both models

### Inference

- **Random Forest**: Hold sign steady for instant detection
- **Transformer**: Perform full motion naturally
- **Confidence**: Green (â‰¥80%) is reliable, Red (<60%) may be wrong
- **Unknown signs**: Shows when model is uncertain

---

## ğŸ› ï¸ Troubleshooting

### "Processing..." stuck on Transformer

- **Fixed**: Cooldown mechanism stores last prediction
- Wait 2 seconds between predictions

### Model not loading

- Check file paths in `config.py`
- Ensure models exist in `./models/` directory
- Retrain if necessary

### Low accuracy

- Collect more training data
- Ensure consistent lighting
- Check hand visibility in camera
- Verify correct model for sign type

### Camera not working

- Check `CAMERA_INDEX` in `config.py`
- Try `CAMERA_INDEX = 1` for external camera
- Grant camera permissions

---

## ğŸ“¦ Requirements

```
opencv-python
mediapipe
numpy
scikit-learn
scipy
pandas
matplotlib
seaborn
flask
flask-cors
torch>=2.0.0
torchvision>=0.15.0
```

**Platform**: macOS (Apple Silicon GPU support), Windows, Linux

---

## ğŸš€ Future Enhancements

- [ ] Web UI for Transformer sign addition (with WebSocket progress)
- [ ] More sign languages (BSL, ISL, etc.)
- [ ] Mobile app (iOS/Android)
- [ ] Real-time translation mode
- [ ] Sign language learning mode
- [ ] Multi-hand gesture recognition
- [ ] Export trained models (ONNX, CoreML)

---

## ğŸ™ Acknowledgments

- **MediaPipe**: Hand landmark detection
- **PyTorch**: Transformer model framework
- **scikit-learn**: Random Forest implementation
- **Flask**: Web application framework
- **Sign Language Detector Python Repo**: [computervisioneng](https://github.com/computervisioneng/sign-language-detector-python)

---

**Happy Signing!** ğŸ¤Ÿ
